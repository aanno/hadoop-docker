FROM docker.io/openjdk:11-jdk AS jdk

FROM docker.io/python:3.11

USER root

# --------------------------------------------------------
# JAVA
# --------------------------------------------------------
RUN \
    apt update \
    && apt-get install -y --no-install-recommends \
    python3-launchpadlib \
    software-properties-common
# RUN add-apt-repository ppa:openjdk-r/ppa
# RUN apt update
# RUN apt install -y --no-install-recommends \
#     openjdk-8-jdk
# For AMD based architecture use
# ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64/
COPY --from=jdk /usr/local/openjdk-11 /usr/lib/jvm/java-11-openjdk/
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk/
ENV PATH=$JAVA_HOME/bin:$PATH

# --------------------------------------------------------
# HADOOP
# --------------------------------------------------------

ENV HADOOP_VERSION=3.3.6
ENV HADOOP_HOME=/opt/hadoop
ENV HADOOP_CONF_DIR=/etc/hadoop
ENV MULTIHOMED_NETWORK=1
ENV PATH=$HADOOP_HOME/bin/:$PATH

RUN \
    set -x \
    && tar -xvf /tmp/hadoop.tar.gz -C /opt/ \
    && mv /opt/hadoop-${HADOOP_VERSION} ${HADOOP_HOME} \
    && ln -s ${HADOOP_HOME}/etc/hadoop /etc/hadoop \
    && mkdir /opt/hadoop/logs \
    && mkdir /hadoop-data

ADD entrypoint.sh /entrypoint.sh
RUN chmod a+x /entrypoint.sh

COPY conf/core-site.xml $HADOOP_CONF_DIR/core-site.xml
COPY conf/hdfs-site.xml $HADOOP_CONF_DIR/hdfs-site.xml
COPY conf/mapred-site.xml $HADOOP_CONF_DIR/mapred-site.xml
COPY conf/yarn-site.xml $HADOOP_CONF_DIR/yarn-site.xml

# ADD hadoop.env /hadoop.env

# RUN set -x && cd / && ./entrypoint.sh

# --------------------------------------------------------
# SPARK
# --------------------------------------------------------

ENV SPARK_VERSION=3.5.1
ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH
# ENV HADOOP_CONF_DIR=$SPARK_HOME/conf
ENV PYSPARK_PYTHON=python3
ENV PYTHONHASHSEED=1

RUN \
    set -x \
    && tar -xvzf /tmp/spark.tar.gz -C /opt/ \
    && mv /opt/spark-${SPARK_VERSION}-bin-hadoop3 ${SPARK_HOME}

ADD conf/core-site.xml $SPARK_HOME/conf
ADD conf/yarn-site.xml $SPARK_HOME/conf

# --------------------------------------------------------
# HIVE
# --------------------------------------------------------

# HIVE3 needs jdk8 and is out of scope
ENV HIVE_VERSION=4.0.0-beta-1
ENV HIVE_HOME=/opt/hive
ENV PATH=$HIVE_HOME/bin:$PATH

RUN \
    set -x \
    && tar -xvzf /tmp/hive.tar.gz -C /opt/ \
    && mv /opt/apache-hive-${HIVE_VERSION}-bin ${HIVE_HOME} \
    && cp /tmp/postgresql.jar ${HIVE_HOME}/lib

# --------------------------------------------------------
# FLINK
# --------------------------------------------------------

ENV FLINK_VERSION=1.18.1
ENV SCALA_VERSION=2.12
ENV FLINK_HOME=/opt/flink
ENV PATH=$FLINK_HOME/bin:$PATH

RUN \
    set -x \
    && tar -xvzf /tmp/flink.tar.gz -C /opt/ \
    && mv /opt/flink-${FLINK_VERSION} ${FLINK_HOME}

#=========
# INSTALL PYTHON DEPS
#=========
RUN \
    apt-get update && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get install -y --no-install-recommends \
    gcc \
    g++ \
    subversion \
    python3-dev \
    gfortran \
    build-essential \
    libopenblas-dev \
    liblapack-dev \
    libqpdf-dev \
    pkg-config \
    libzbar-dev \
    python3-dev \
    libpython3-dev \
    qpdf \
    xvfb \
    gconf-service \
    libasound2 \
    libatk1.0-0 \
    libcairo2 \
    libcups2 \
    libfontconfig1 \
    libgdk-pixbuf2.0-0 \
    libgtk-3-0 \
    libnspr4 \
    libpango-1.0-0 \
    libxss1 \
    fonts-liberation \
    libappindicator1 \
    libnss3 \
    lsb-release \
    xdg-utils \
    wget \
    && apt-get autoremove -yqq --purge \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

ADD requirements.txt /requirements.txt

RUN \
    pip install --default-timeout=100 --upgrade pip \
    && pip install pikepdf Cython numpy wheel setuptools --force-reinstall \
    && pip install -r /requirements.txt \
    && pip cache dir
    # && rm -rf /root/.cache/*
